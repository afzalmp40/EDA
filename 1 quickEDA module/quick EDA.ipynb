{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60fd3e95-58a0-4a4b-ab0a-46fc61f8cc06",
   "metadata": {},
   "source": [
    "    Module made for quick EDA.\n",
    "    -Detect and handle outliers using methods like Z score and IQR.\n",
    "    -Outlier handling methods include removing and compressing. \n",
    "    -Plot correlation heatmap using \"correlation\" function.\n",
    "\n",
    "    Available functions:\n",
    "\n",
    "        UNIVARIATE ANALYSIS:\n",
    "        ----------------------\n",
    "        five_point_summary: Prints five point summary of a feature.\n",
    "        outliers_z_score: Analyse outliers using Z score.\n",
    "        outliers_IQR: Analyse outliers using IQR.\n",
    "        analysis_quant: Analyse quantative features.\n",
    "        analysis_cate: Analyse categorical features.\n",
    "        handle_outliers: Handle outliers.\n",
    "\n",
    "        ____________________________________________________________\n",
    "\n",
    "        BIVARIATE ANALYSIS:\n",
    "        ----------------------\n",
    "        correlation: Plot correlation heatmap for a dataframe.\n",
    "        multiplot: plot multiple plots like correlation heatmap,\n",
    "                   pairwise scatterplot and histogram in single plot.\n",
    "\n",
    "        ____________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699ebbd-e1b1-493c-939d-3c0eafe769bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean as np_mean ,std as np_std\n",
    "from pandas import DataFrame as pd_DataFrame\n",
    "from matplotlib.pyplot import subplots as plt_subplots, show as plt_show\n",
    "from seaborn import histplot as sns_histplot, boxplot as sns_boxplot, barplot as sns_barplot, heatmap as sns_heatmap "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc330490-7cb4-4ee0-a12d-5fc3ee4c666e",
   "metadata": {},
   "source": [
    "### Garbage cleaner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148a2d2-7b37-4069-aef9-1344bd3596b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garbage_cleaner():\n",
    "    '''\n",
    "    clears all variables in local namespace\n",
    "    '''\n",
    "    \n",
    "    keys=locals().keys()\n",
    "    del(keys)\n",
    "    \n",
    "    from gc import collect\n",
    "    collect()\n",
    "    del(collect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521db8e8-31d5-49bd-aa2c-4c7f37cc9a03",
   "metadata": {},
   "source": [
    "# UNIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf4cb7-fdbe-4793-841e-20967d2fd752",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 5 point summary fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da63e67-bdc1-461b-8181-a34f47061e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_point_summary(df, columns='all_the_columns'):\n",
    "    '''\n",
    "    Prints five point summary of a feature.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "        df: \n",
    "            a pandas dataframe\n",
    "        \n",
    "        columns: default('all_the_columns') \n",
    "            list of column names.\n",
    "            (if list of columns is not passed then\n",
    "            all columns are analysed)\n",
    "    ________________\n",
    "    Returns: \n",
    "        None\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # converting singular value of str to list \n",
    "    if type(columns)==str:\n",
    "        # if list of columns is not passed then all columns are analysed\n",
    "        if columns=='all_the_columns':\n",
    "            columns=df.columns\n",
    "        # else the passed string is converted to a list\n",
    "        else:\n",
    "            columns=[columns]\n",
    "    \n",
    "    for column in columns:\n",
    "        print('5 point summary for:', column)\n",
    "        \n",
    "        # extracting and printing the five point summary from describe function\n",
    "        print(df[[column]].describe().iloc[3:] )\n",
    "        print('---------------------------------')\n",
    "        \n",
    "    garbage_cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e80411-e43e-4ef4-aaf3-ff68c57a32a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### outlier analysis using Z score fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea773f83-1d67-45f9-a948-8da7892b7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_z_score(df, columns='all_the_columns', mode='print'):\n",
    "    '''\n",
    "    Analyse outliers using Z score.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "        df: \n",
    "            a pandas dataframe\n",
    "        \n",
    "        columns: default('all_the_columns') \n",
    "            list of column names.\n",
    "            (if list of columns is not passed then\n",
    "            all columns are analysed)\n",
    "                 \n",
    "        mode: {'print': 'only prints outliers',\n",
    "               'return': 'returns outliers dataframe' \n",
    "              }\n",
    "    ________________\n",
    "    Returns: \n",
    "        ('upper', 'lower', 'outliers_with_z') when mode='return'\n",
    "        \n",
    "        None when mode='print'\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    from numpy import mean as np_mean ,std as np_std\n",
    "    from pandas import DataFrame as pd_DataFrame\n",
    "    \n",
    "    # converting singular value of str to list \n",
    "    if type(columns)==str:\n",
    "        # if list of columns is not passed then all columns are analysed\n",
    "        if columns=='all_the_columns':\n",
    "            columns=df.columns\n",
    "        # else the passed string is converted to a list\n",
    "        else:\n",
    "            columns=[columns]\n",
    "        \n",
    "    for column in columns:\n",
    "        \n",
    "        ###CALCULATIONS###\n",
    "        \n",
    "        # storing the feature as a series \n",
    "        feature=df[column]\n",
    "        \n",
    "        # calculate mean and stdev\n",
    "        mean = np_mean(feature)\n",
    "        stdev = np_std(feature)\n",
    "        \n",
    "        # calculate outlier limits via Z score\n",
    "        lower= -3*stdev + mean\n",
    "        upper=  3*stdev + mean\n",
    "        \n",
    "        # calculating Z score for features\n",
    "        Z=(feature-mean)/stdev\n",
    "        \n",
    "        # creating a mask to subset only outlier values( abs(z) > 3 )\n",
    "        mask=abs( Z )>3\n",
    "        \n",
    "        # a dataframe storing the outliers and their z scores\n",
    "        outliers_with_z=pd_DataFrame( {\n",
    "                                'outliers' : feature[mask],\n",
    "                                'Z-score'  : Z[mask] \n",
    "        }).sort_values(by='outliers')\n",
    "        \n",
    "        if mode=='return':\n",
    "            return upper, lower, outliers_with_z\n",
    "        \n",
    "        else:\n",
    "            ###PRINTING THE RESULTS###\n",
    "            print( 'OUTLIERS in ' + column + ' via Z score\\n' )\n",
    "            print('Outlier limits:\\nlower limit:', lower, '\\nupper limit:', upper)\n",
    "            print()\n",
    "            print('Total outliers:', outliers_with_z.shape[0] )\n",
    "            \n",
    "            if outliers_with_z.shape[0]!=0:\n",
    "                \n",
    "                if len(outliers_with_z)>10:\n",
    "                    print(outliers_with_z[:5],'\\n.\\n.')\n",
    "                    print(outliers_with_z[-5:])\n",
    "                else:\n",
    "                    print(outliers_with_z)\n",
    "                \n",
    "            print('---------------------------------')\n",
    "            \n",
    "    garbage_cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a416bb-555a-4c2f-87a6-264ed13a7b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### outlier analysis using IQR fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0351a7-3dd6-47ea-be15-2dde791dcc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_IQR(df, columns='all_the_columns', mode='print'):\n",
    "    '''\n",
    "    Analyse outliers using IQR.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "        df: a pandas dataframe\n",
    "        \n",
    "        columns: default('all_the_columns') list of column names.\n",
    "                 (if list of columns is not passed then\n",
    "                 all columns are analysed)\n",
    "                 \n",
    "        mode: {'print': 'only prints outliers',\n",
    "               'return': 'returns outliers dataframe' \n",
    "              }\n",
    "    ________________\n",
    "    Returns: \n",
    "        ('upper', 'lower', 'outliers_with_IQR') when set to 'return'\n",
    "        None when set to 'print' \n",
    "        \n",
    "    ''' \n",
    "    \n",
    "    from pandas import DataFrame as pd_DataFrame\n",
    "    \n",
    "    \n",
    "    # converting singular value of str to list \n",
    "    if type(columns)==str:\n",
    "        # if list of columns is not passed then all columns are analysed\n",
    "        if columns=='all_the_columns':\n",
    "            columns=df.columns\n",
    "        # else the passed string is converted to a list\n",
    "        else:\n",
    "            columns=[columns]\n",
    "        \n",
    "    for column in columns:\n",
    "        \n",
    "        ###CALCULATIONS###\n",
    "        # storing the feature as a series \n",
    "        feature=df[column]\n",
    "        \n",
    "        # extracting quartile1, quartile3 from df.describe\n",
    "        q1,q3=feature.describe().iloc[[4,6]]\n",
    "\n",
    "        # calculating iqr\n",
    "        iqr=q3-q1\n",
    "\n",
    "        # calculate outlier limits using iqr and tukey value of 1.5\n",
    "        upper= q3 + 1.5*iqr\n",
    "        lower= q1 - 1.5*iqr\n",
    "\n",
    "        #creating a mask for filtering\n",
    "        mask= (feature<lower) | (feature>upper)\n",
    "        \n",
    "        # filter and store feature using outlier limits\n",
    "        outliers_with_IQR= feature[mask].sort_values()\n",
    "        outliers_with_IQR.columns='outliers'\n",
    "\n",
    "        if mode=='return':\n",
    "            return upper, lower, outliers_with_IQR\n",
    "        else:\n",
    "            ###PRINTING THE RESULTS###\n",
    "            print( 'OUTLIERS in '+ column +' via IQR\\n' )\n",
    "            print('Outlier limits:\\nlower limit:',lower,'\\nupper limit:',upper)            \n",
    "            print()\n",
    "            print('Total outliers:', outliers_with_IQR.shape[0] )\n",
    "            \n",
    "            if outliers_with_IQR.shape[0]!=0:\n",
    "                \n",
    "                if len(outliers_with_IQR)>10:\n",
    "                    outliers_with_IQR=pd_DataFrame(outliers_with_IQR)\n",
    "                    print(outliers_with_IQR[:5],'\\n.\\n.')\n",
    "                    print(outliers_with_IQR[-5:])\n",
    "                else:\n",
    "                    print(outliers_with_IQR)\n",
    "                \n",
    "            print('---------------------------------')\n",
    "    \n",
    "    garbage_cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92025e86-73ae-465a-8ae3-9fee19fa95b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analysis of quantitative columns fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a5b7d-3302-43dc-b9d9-936beeed93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_quant(df, columns='all_the_columns', figsize=(20,2), dpi=120):\n",
    "    '''\n",
    "    Analyse quantative features.\n",
    "    Prints five point summary and outliers via Z score and IQR. \n",
    "    Plots boxplot and histogram to visualise outliers.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "        df: a pandas dataframe\n",
    "        \n",
    "        columns: default('all_the_columns') list of column names.\n",
    "                 (if list of columns is not passed then\n",
    "                 all columns are analysed)\n",
    "                 \n",
    "        figsize: default(20,7) set figure size\n",
    "        \n",
    "        dpi: default(120) set figure dpi\n",
    "    ________________\n",
    "    Returns: \n",
    "        None\n",
    "        \n",
    "    '''\n",
    "\n",
    "    from matplotlib.pyplot import subplots as plt_subplots, show as plt_show\n",
    "    from seaborn import histplot as sns_histplot, boxplot as sns_boxplot\n",
    "    \n",
    "    # converting singular value of str to list \n",
    "    if type(columns)==str:\n",
    "        # if list of columns is not passed then all columns are analysed\n",
    "        if columns=='all_the_columns':\n",
    "            columns=df.columns\n",
    "        # else the passed string is converted to a list\n",
    "        else:\n",
    "            columns=[columns]\n",
    "    \n",
    "    for column in columns:\n",
    "\n",
    "        # storing feature as series\n",
    "        feature=df[column]\n",
    "        \n",
    "        print('\\t\\t\\t\\tANALYSIS OF:', column ,'\\n')\n",
    "        \n",
    "        if feature.dtype=='object':\n",
    "            print(f'Feature \"{column}\" might be categorical.\\nPlease use \"analysis_cate\" function.')\n",
    "            print('___________________________________________________________________________________________________________')\n",
    "            continue\n",
    "\n",
    "        # five point summary\n",
    "        five_point_summary(df, column)   \n",
    "\n",
    "        # z score and outliers\n",
    "        outliers_z_score(df, column)  \n",
    "\n",
    "        # iqr and outliers\n",
    "        outliers_IQR(df, column)      \n",
    "\n",
    "        ###PLOTTING###\n",
    "        fig, axes = plt_subplots(1, 2, sharex=True, figsize=figsize, dpi=dpi)\n",
    "        # boxplot\n",
    "        sns_boxplot(ax=axes[0] , x=feature)  \n",
    "        # histogram\n",
    "        sns_histplot(ax=axes[1], data=feature, bins=50)    \n",
    "\n",
    "        plt_show()\n",
    "        print('___________________________________________________________________________________________________________')\n",
    "    \n",
    "    garbage_cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a54e299-a6e2-4b8b-b8b3-fa0a53945181",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analysis of categorical columns fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e44b9e-c78c-4674-b09e-e43fd6dcf6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_cate(df, columns='all_the_columns', figsize=(12,3), dpi=120, force=False):    \n",
    "    '''\n",
    "    Analyse categorical features.\n",
    "    Prints unique values and their counts. \n",
    "    Plots barplot and pie chart.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "        df: a pandas dataframe\n",
    "        \n",
    "        columns: default('all_the_columns') list of column names.\n",
    "                 (if list of columns is not passed then\n",
    "                 all columns are analysed)\n",
    "                 \n",
    "        figsize: default(20,7) set figure size\n",
    "        \n",
    "        dpi: default(120) set figure dpi\n",
    "    \n",
    "        force: default(False) whether to proceed with a feature that\n",
    "               might be numerical( !!!MAY CAUSE MEMORY LEAK!!! ) \n",
    "    ________________\n",
    "    Returns: \n",
    "        None\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    from matplotlib.pyplot import subplots as plt_subplots, show as plt_show\n",
    "    from seaborn import barplot as sns_barplot\n",
    "    \n",
    "    # converting singular value of str to list \n",
    "    if type(columns)==str:\n",
    "        # if list of columns is not passed then all columns are analysed\n",
    "        if columns=='all_the_columns':\n",
    "            columns=df.columns\n",
    "        # else the passed string is converted to a list\n",
    "        else:\n",
    "            columns=[columns]\n",
    "    \n",
    "    for column in columns:\n",
    "        \n",
    "        # storing feature as series\n",
    "        feature=df[column]\n",
    "        \n",
    "        print('\\t\\t\\t\\tANALYSIS OF:', column ,'\\n')\n",
    "\n",
    "        # calculate no. of classes in the features and warn that feature might be numerical\n",
    "        if force==False:\n",
    "            if feature.nunique()>20:\n",
    "                print(f'The feature \"{column}\" might be numerical. Please try the \"analysis_quant\" function.\\nIncase you want to proceed anyways, set \"force\" parameter to True.\\n(Caution!!! May cause memory leak.)')\n",
    "                print('______________________________________________________________________________________________________')\n",
    "                continue\n",
    "                \n",
    "        if force==True:\n",
    "            print(f'The feature \"{column}\" might be numerical. Proceeding anyways.')\n",
    "        \n",
    "        # calculate and print unique values and their counts\n",
    "        values=feature.value_counts()\n",
    "        print('No. of UNIQUE values:')\n",
    "        print(values)\n",
    "        print()\n",
    "\n",
    "        ###PLOTTING###\n",
    "        fig, axes =  plt_subplots(1, 2, figsize=figsize, dpi=dpi)\n",
    "        # barplot\n",
    "        sns_barplot(x=values.index, y=values, ax=axes[0])\n",
    "        axes[0].set_ylabel('count')\n",
    "        # pie chart\n",
    "        axes[1].pie(x=values, labels=values.index )\n",
    "        \n",
    "        plt_show()\n",
    "        print('_____________________________________________________________________________________________________________________')\n",
    "        \n",
    "    garbage_cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c05511-c66c-496b-b21a-5ba68b56d2af",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handle outliers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57052cc-f9f6-422d-b4f6-fdc7537eb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, columns, using='Z', action='compress', custom_intervals=(None,None)):\n",
    "    '''\n",
    "    Handle outliers.\n",
    "    Remove or compress outliers from dataframe(inplace) by using\n",
    "    either Z score or IQR. Prints the removed/compressed values.\n",
    "\n",
    "    Parameters:\n",
    "    ----------------\n",
    "        df: a pandas dataframe\n",
    "        \n",
    "        columns: list of column names from which outliers are to be\n",
    "                 handled\n",
    "                 \n",
    "        using: {'Z': Z score,\n",
    "                'IQR': Inter quartile range\n",
    "                'custom' : Provide custom lower and upper limits\n",
    "                           Only works if single column passed\n",
    "                }\n",
    "                \n",
    "        action: {'compress': compresses the outliers to the extreme \n",
    "                             values using the chosen method\n",
    "                 'remove': removes the outliers using the chosen method\n",
    "                }\n",
    "        \n",
    "        custom_intervals : default( (None,None) )\n",
    "            Supply this when using=\"custom\" \n",
    "            Intervals using which outliers will be handled\n",
    "            Provide custom intervals as a tuple in the format:\n",
    "            (lower limit, upper limit)\n",
    "    ________________\n",
    "    Returns: \n",
    "        None\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    from pandas import DataFrame as pd_DataFrame, concat as pd_concat\n",
    "    from matplotlib.pyplot import subplots as plt_subplots, show as plt_show\n",
    "    from seaborn import histplot as sns_histplot \n",
    "    \n",
    "    # converting single value to list\n",
    "    if type(columns)==str:\n",
    "        columns=[columns]\n",
    "    \n",
    "    for column in columns:\n",
    "        before=df[column].copy()\n",
    "        \n",
    "        if using.strip().upper()=='CUSTOM': \n",
    "            if custom_intervals != (None,None):\n",
    "                # setting lower and upper limit as the custom_interval \n",
    "                lower,upper=custom_intervals\n",
    "                if lower==None: lower=df[column].min()\n",
    "                if upper==None: upper=df[column].max()\n",
    "                #making the outliers dataframe \n",
    "                outliers= pd_concat( (df[df[column]<lower], df[df[column]>upper]) )[column].sort_values()\n",
    "            else:\n",
    "                using='Z'\n",
    "                print('Using the z score method as custom intervals were not provided')\n",
    "            \n",
    "        # if IQR method is chosen\n",
    "        if using.strip().upper()=='IQR':\n",
    "            # calling 'outliers_IQR_score' function to retrieve limits, outliers\n",
    "            upper, lower, outliers = outliers_IQR(df, column, mode='return')\n",
    "\n",
    "        # if Z score method is chosen\n",
    "        if using.strip().upper()=='Z':\n",
    "            # calling 'outliers_z_score' function to retrieve limits, outliers\n",
    "            upper, lower, outliers = outliers_z_score(df, column, mode='return')\n",
    "        \n",
    "        # if remove option is chosen\n",
    "        if action=='remove':\n",
    "            # dropping the outliers and printing them as removed\n",
    "            df.drop(index=outliers.index, inplace=True)\n",
    "            print('Removed the following outliers in {column}:\\n')\n",
    "\n",
    "        # if compress action is chosen(default)\n",
    "        if action=='compress':\n",
    "            # compressing the outliers\n",
    "            df.loc[ df[column] > upper, column] = upper\n",
    "            df.loc[ df[column] < lower, column] = lower\n",
    "            print(f'Compressed the following outliers in {column}:\\n')\n",
    "            \n",
    "        print('Total outliers:',len(outliers))\n",
    "        if len(outliers)>10:\n",
    "            outliers=pd_DataFrame(outliers)\n",
    "            print(outliers[:5],'\\n.\\n.')\n",
    "            print(outliers[-5:])\n",
    "        else:\n",
    "            print(outliers)\n",
    "            \n",
    "        after=df[column]\n",
    "        # plot the difference after handling outliers\n",
    "        fig,ax=plt_subplots(1,2, figsize=(20,3), dpi=100)\n",
    "        \n",
    "        #before.hist(bins=50, ax=ax[0])\n",
    "        sns_histplot(ax=ax[0], data=before, bins=50) \n",
    "        ax[0].set_title(f'{column} before')\n",
    "\n",
    "        #after.hist(bins=50, ax=ax[1])\n",
    "        sns_histplot(ax=ax[1], data=after, bins=50) \n",
    "        ax[1].set_title(f'{column} after')\n",
    "        plt_show()\n",
    "            \n",
    "        print('_____________________________________________________________________________________________________________________')\n",
    "\n",
    "    garbage_cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf6f4e-8644-4723-b9d2-ff0b49dafd12",
   "metadata": {},
   "source": [
    "# BIVARIATE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81975d73-77c3-48d2-9a7e-4ef509adfa4a",
   "metadata": {},
   "source": [
    "### Plot Correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4be26-5904-4917-87b8-6e287e9fc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df, figsize=(15,10), dpi=100):\n",
    "    '''\n",
    "    Plot correlation heatmap for a dataframe.\n",
    "    Includes both pearson and spearman correlation.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------------\n",
    "        df: a pandas dataframe\n",
    "        figsize: default(15,10) set figure size\n",
    "        dpi: default(100) set figure dpi\n",
    "    ________________\n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    from matplotlib.pyplot import subplots as plt_subplots, show as plt_show\n",
    "    from seaborn import heatmap as sns_heatmap \n",
    "    \n",
    "    fig , ax= plt_subplots(1,2, figsize=figsize, dpi=dpi)\n",
    "\n",
    "    # plotting pearson correlation heatmap\n",
    "    pearson=df.corr()\n",
    "    ax[0].set_title('pearson')\n",
    "    sns_heatmap(pearson, cmap='RdBu', square=True, annot=True, fmt='.2f', vmin=-1, vmax=1, ax=ax[0])\n",
    "\n",
    "    # plotting spearman correlation heatmap\n",
    "    spearman=df.corr(method='spearman')\n",
    "    ax[1].set_title('spearman')\n",
    "    sns_heatmap(spearman, cmap='RdBu', square=True, annot=True, fmt='.2f', vmin=-1, vmax=1, ax=ax[1])\n",
    "\n",
    "    plt_show()\n",
    "    \n",
    "    garbage_cleaner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979eb96-5dba-47bb-ac01-16f10100efbe",
   "metadata": {},
   "source": [
    "### Multiplot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0effab8-8feb-45fa-ba1d-a58a785c511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplot(df, line_width=1, line_color='darkblue', point_size=0.5, point_color='darkcyan', alpha=0.5, height=1, dpi=150, aspect=1.5 ):    \n",
    "    '''\n",
    "    plot multiple plots like correlation(pearson) heatmap, pairwise scatterplot \n",
    "    and histogram in a single plot\n",
    "    \n",
    "    Parameters :\n",
    "    ---------------\n",
    "    df : Default(None)\n",
    "        a pandas dataframe\n",
    "    \n",
    "    linewidth : default(2)\n",
    "        width of regression line\n",
    "        \n",
    "    line_color : default('blue')\n",
    "        color of regression line\n",
    "        \n",
    "    point_size : default(0.5)\n",
    "        size of scatter points\n",
    "        \n",
    "    point_color : default('darkcyan')\n",
    "        color of scatter points\n",
    "        \n",
    "    alpha : default(0.5)\n",
    "        transparency value for scatter points\n",
    "    \n",
    "    height : default(1)\n",
    "        Height of figure\n",
    "        \n",
    "    dpi : default(100)\n",
    "        dpi of figure\n",
    "        \n",
    "    aspect : default(1.5)\n",
    "        aspect ratio of figure\n",
    "    _______________\n",
    "    returns : None\n",
    "    '''\n",
    "    \n",
    "    from seaborn import PairGrid as sns_pairgrid, histplot as sns_histplot, despine as sns_despine, regplot as sns_regplot\n",
    "    from matplotlib.pyplot import gca as plt_gca, scatter as  plt_scatter, Normalize as plt_normalize, get_cmap as plt_get_cmap, show as plt_show\n",
    "    from scipy.stats import pearsonr \n",
    "    import matplotlib.style as style\n",
    "    style.use(\"default\")\n",
    "\n",
    "    def corrfunc(x, y, **kwds):\n",
    "        cmap = kwds['cmap']\n",
    "        norm = kwds['norm']\n",
    "        ax = plt_gca()\n",
    "        ax.tick_params(bottom=False, top=False, left=False, right=False)\n",
    "        sns_despine(ax=ax, bottom=True, top=True, left=True, right=True)\n",
    "        r, _ = pearsonr(x, y)\n",
    "        facecolor = cmap(norm(r))\n",
    "        ax.set_facecolor(facecolor)\n",
    "        lightness = (max(facecolor[:3]) + min(facecolor[:3]) ) / 2\n",
    "        ax.annotate(f\"r={r:.2f}\", xy=(.5, .5), xycoords=ax.transAxes,\n",
    "                    color='white' if lightness < 0.7 else 'black', size=10, ha='center', va='center')\n",
    "\n",
    "\n",
    "    #df=fetch_california_housing(as_frame=True).frame #[['MedInc','HouseAge']]\n",
    "\n",
    "    g = sns_pairgrid(df, height=height, aspect=aspect)\n",
    "    #g.map_lower(plt_scatter, s=1)\n",
    "    g.map_lower(sns_regplot, ci=0, scatter_kws={'s':point_size, 'alpha':alpha, 'color':point_color}, line_kws={'linewidth':line_width, 'color':line_color})\n",
    "    g.map_diag(sns_histplot, kde=False)\n",
    "    g.map_upper(corrfunc, norm=plt_normalize(vmin=-.5, vmax=.5), cmap=plt_get_cmap('RdBu'))\n",
    "    g.fig.subplots_adjust(wspace=0.06, hspace=0.06) # equal spacing in both directions\n",
    "    g.fig.dpi=dpi\n",
    "    plt_show()\n",
    "\n",
    "    style.use(\"seaborn-darkgrid\")\n",
    "    #del(sns_pairgrid,sns_histplot,sns_despine,plt_gca,plt_scatter,plt_normalize,plt_get_cmap,plt_show,pearsonr,style)\n",
    "    \n",
    "    garbage_cleaner()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
